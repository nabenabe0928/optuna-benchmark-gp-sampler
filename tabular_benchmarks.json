{
    "init_lr": [
        5e-4,
        1e-3,
        5e-3,
        1e-2,
        5e-2,
        1e-1
    ],
    "lr_schedule": [
        "cosine",
        "const"
    ],
    "batch_size": [
        8,
        16,
        32,
        64
    ],
    "activation_fn_1": [
        "relu",
        "tanh"
    ],
    "activation_fn_2": [
        "relu",
        "tanh"
    ],
    "dropout_1": [
        0.0,
        0.3,
        0.6
    ],
    "dropout_2": [
        0.0,
        0.3,
        0.6
    ],
    "n_units_1": [
        16,
        32,
        64,
        128,
        256,
        512
    ],
    "n_units_2": [
        16,
        32,
        64,
        128,
        256,
        512
    ]
}
